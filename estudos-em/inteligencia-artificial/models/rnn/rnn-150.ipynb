{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "source": [
        "## Libraries and config"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /home/tuca/.local/lib/python3.8/site-packages (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (3.17.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (45.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.22.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.30.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/tuca/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/tuca/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tuca/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tuca/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tuca/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tuca/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.1.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/tuca/.local/lib/python3.8/site-packages (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/tuca/.local/lib/python3.8/site-packages (1.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /home/tuca/.local/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/tuca/.local/lib/python3.8/site-packages (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sklearn in /home/tuca/.local/lib/python3.8/site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /home/tuca/.local/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: statsmodels in /home/tuca/.local/lib/python3.8/site-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.6.3)\n",
            "Requirement already satisfied: patsy>=0.5 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.2.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.21->statsmodels) (2019.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.21->statsmodels) (2.7.3)\n",
            "Requirement already satisfied: six in /home/tuca/.local/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/tuca/.local/lib/python3.8/site-packages (3.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.16 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.7.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /home/tuca/.local/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras==2.3.1 in /home/tuca/.local/lib/python3.8/site-packages (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras==2.3.1) (5.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/tuca/.local/lib/python3.8/site-packages (from keras==2.3.1) (1.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install statsmodels\n",
        "!pip install matplotlib\n",
        "!pip install keras==2.3.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3tKGcLkrmvV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "import pandas as pd # data manipulation library\n",
        "import numpy as np # math library\n",
        "\n",
        "import sklearn.metrics as sklm # metrics\n",
        "import skll.metrics as skllm\n",
        "import statsmodels as sm # statistical models\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/tuca/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5e3b0a79b145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrictVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranspose_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpy_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/tuca/.local/lib/python3.8/site-packages/keras/utils/generic_utils.py)"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam, Adagrad\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "import tensorflow as tf # machine learning library\n",
        "import os\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.random.set_random_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "from keras.layers import SimpleRNN"
      ]
    },
    {
      "source": [
        "## Utils"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_data(flow_interval):\n",
        "    path = \"{0}dataset/dataset_flow_{1}.csv\".format(PATH, flow_interval)\n",
        "    print(PATH)\n",
        "    data = pd.read_csv(path, ';')\n",
        "    \n",
        "    data['Flow'].apply(int)\n",
        "    data['AveSpeed'].apply(float)\n",
        "    data['Density'].apply(float)\n",
        "    data['Sunday'].apply(int)\n",
        "    data['Monday'].apply(int)\n",
        "    data['Tuesday'].apply(int)\n",
        "    data['Wednesday'].apply(int)\n",
        "    data['Thursday'].apply(int)\n",
        "    data['Friday'].apply(int)\n",
        "    data['Saturday'].apply(int)\n",
        "      \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store(obj, path, name):\n",
        "  with open(\"{0}{1}/{2}.json\".format(PATH, path, name), 'w') as json_file:\n",
        "    json.dump(obj, json_file, sort_keys=True, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(data, useB, n_steps, n_future):\n",
        "  \"\"\" Generate Dataset\n",
        "  \n",
        "  Generate a dataset provided a sequence. Reshape the sequence in rolling intervals from [samples, timesteps] into \n",
        "  [samples, timesteps, features] and split the sequence. The split the sequence in rolling intervals with a corresponding value \n",
        "  like the example bellow.\n",
        "\n",
        "  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])\n",
        "  \n",
        "  Arguments:\n",
        "    raw_seq: the sequence to reshape.\n",
        "    useB: if the dataset is more complex or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "\n",
        "  sequence = np.array(data if useB else data['Flow'])\n",
        "\n",
        "  n = len(sequence)\n",
        "  X, Y = list(), list()\n",
        "\n",
        "  for i in range(n):\n",
        "    j = i + n_steps\n",
        "    k = j + n_future\n",
        "\n",
        "    if k >= n:\n",
        "      break\n",
        "\n",
        "    seq_x, seq_y = sequence[i:j], sequence[k]\n",
        "    X.append(seq_x)\t\n",
        "    Y.append(seq_y[0] if useB else seq_y)\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\t\n",
        "  \n",
        "  if not useB:\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate (expected, observed, times, name):\n",
        "  \"\"\" Evaluate Sessions\n",
        "  \n",
        "  Evaluate models by RMSE, NRMSE, MAE, HR, PRE. It will store the \n",
        "  results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each \n",
        "      train&test session.\n",
        "    observed: an array of observed instances of each \n",
        "      train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "    name: the name of the model\n",
        "  \"\"\"\n",
        "  n = len(expected)\n",
        "  flatten = lambda l : [i for sl in l for i in sl]\n",
        "  \n",
        "  # Make the arrays serializable\n",
        "  expected = list(map(list, expected))\n",
        "  observed = list(map(list, observed))\n",
        "  \n",
        "  for i in range(n):\n",
        "    expected[i] = list(map(float, expected[i]))\n",
        "    observed[i] = list(map(float, observed[i]))\n",
        "  \n",
        "  raw = evaluate_raw(expected, observed, times)\n",
        "  \n",
        "  #n_buckets = len(raw['PRE'])\n",
        "  #_pre = [[pre[i] for pre in raw['PRE']] for i in range(n_buckets)]\n",
        "  \n",
        "  eva = {\n",
        "    'TIME': int(sum(times)),\n",
        "    'RMSE': float(np.mean(raw['RMSE'])),\n",
        "    'MAE': float(np.mean(raw['MAE'])),\n",
        "    'Kappa': float(np.mean(raw['Kappa'])),\n",
        "    'HR': float(np.mean(raw['HR'])),\n",
        "    'has_negative': (min(flatten(observed)) < 0),\n",
        "    'raw': raw\n",
        "  }\n",
        "  \n",
        "  print(f\"\\n{name} Final Result:\")\n",
        "  print(f\"\\tTotal Time: {eva['TIME']}s\")\n",
        "  print(f\"\\tRMSE: {eva['RMSE']}\")\n",
        "  print(f\"\\tMAE: {eva['MAE']}\")\n",
        "  print(f\"\\tKappa: {eva['Kappa']}\")\n",
        "  print(f\"\\tHit Ratio: {eva['HR'] * 100}%\")\n",
        "    \n",
        "  return eva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_raw (expected, observed, times):\n",
        "  \"\"\" Evaluate Raw Sessions \n",
        "  \n",
        "  Evaluate each of the train&test sessions by RMSE, NRMSE, MAE, HR, PRE. \n",
        "  It will store the results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each train&test session.\n",
        "    observed: an array of observed instances of each train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(expected)\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [0 if np.isnan(o) else o for o in observed[i]]\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [max(o, 0) for o in observed[i]]\n",
        "  \n",
        "  raw = {\n",
        "    'expected': expected,\n",
        "    'observed': observed,\n",
        "    'TIME': times,\n",
        "    'RMSE': [0] * n,\n",
        "    'Kappa': [0] * n,\n",
        "    'MAE': [0] * n,\n",
        "    'HR': [0] * n,\n",
        "  }\n",
        "  \n",
        "  for i in range(n):\n",
        "    Y = expected[i]\n",
        "    Y_hat = observed[i]\n",
        "    time = times[i]\n",
        "\n",
        "    raw['RMSE'][i] = np.sqrt(sklm.mean_squared_error(Y, Y_hat))\n",
        "    raw['MAE'][i] = sklm.mean_absolute_error(Y, Y_hat)\n",
        "    raw['Kappa'][i] = skllm.kappa(Y, Y_hat)\n",
        "    raw['HR'][i] = evaluate_precision_hit_ratio(Y, Y_hat)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      print(f\"({i+1}/{n}) Test Size: {len(Y)}, Time: {time}s\")\n",
        "      print(f\"\\tRMSE: {raw['RMSE'][i]}\")\n",
        "      print(f\"\\tMAE: {raw['MAE'][i]}\")\n",
        "      print(f\"\\tKappa: {raw['Kappa'][i]}\")\n",
        "      print(f\"\\tHit Ratio: {raw['HR'][i] * 100}%\")\n",
        "\n",
        "  return raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_precision_hit_ratio (Y, Y_hat):\n",
        "  \"\"\" Trend Prediction Ratio Calculation\n",
        "  \n",
        "  Calculates the ratio of up/down prediction.\n",
        "  \n",
        "  Arguments:\n",
        "    Y: the expected dataset.\n",
        "    Y_hat: the observed dataset.\n",
        "  \"\"\"\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    if i < N_FUTURE:\n",
        "      continue\n",
        "      \n",
        "    exp = Y[i] - Y[i - N_FUTURE]\n",
        "    obs = Y_hat[i] - Y[i - N_FUTURE]\n",
        "    \n",
        "    if exp * obs > 0:\n",
        "      cnt += 1\n",
        "    \n",
        "  return cnt / len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_prediction (Y, Y_hat, title):\n",
        "  \"\"\" Plot Prediction\n",
        "  \n",
        "  Plot the prediction (Flow x Time) of what was expected and what\n",
        "  was predicted.\n",
        "  \"\"\"\n",
        "\n",
        "  name = f\"{title}\"\n",
        "  path = f\"plots/prediction/{name}\"\n",
        "  \n",
        "  plt.plot(Y)\n",
        "  plt.plot(Y_hat)\n",
        "  plt.title(f\"Predição do Modelo {title}\")\n",
        "  plt.ylabel('Fluxo')\n",
        "  plt.xlabel('Tempo')\n",
        "  plt.legend(['esperado', 'observado'], loc='upper left')\n",
        "  plt.rcdefaults()\n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.close('all')"
      ]
    },
    {
      "source": [
        "## Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "SEEABLE_PAST = 480 # in minutes\n",
        "PREDICT_IN_FUTURE = 60 # in minutes\n",
        "FLOW_INTERVAL = 150 # the interval size for each flow\n",
        "N_SPLITS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derivated Model Parameters\n",
        "N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past\n",
        "N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next FLOW_INTERVAL minutes)\n",
        "DAY_SIZE = (24 * 60 * 60) // FLOW_INTERVAL  \n",
        "WEEK_SIZE = (7 * 24 * 60 * 60) // FLOW_INTERVAL\n",
        "VERBOSITY = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset(lenX):\n",
        "    return lenX - (WEEK_SIZE*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rnn (data, useB): \n",
        "  global result_data\n",
        "  \n",
        "  name = \"RNN B\" if useB else \"RNN A\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, useB, N_STEPS, N_FUTURE)\n",
        "  \n",
        "  model = Sequential()\t\t\n",
        "\n",
        "  model.add(SimpleRNN(50, activation='relu', input_shape=(X.shape[1], X.shape[2])))\t\t\n",
        "  model.add(Dense(1))\t\t\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse', metrics = [\"accuracy\"])\n",
        "  \n",
        "  pointer = split_dataset(len(X))\n",
        "    \n",
        "  h = model.fit(X[0:pointer], Y[0:pointer], validation_split=0.2, batch_size=64, epochs=15, verbose=2)\n",
        "\n",
        "  return h, [X[(pointer + 1):], Y[(pointer + 1):]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-319afa0d8909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLOW_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-75dea2c1c9a6>\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(data, useB)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FUTURE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ],
      "source": [
        "global result_data\n",
        "  \n",
        "result_data = {\n",
        "    'results': {},\n",
        "    'meta': {\n",
        "      'SEEABLE_PAST': SEEABLE_PAST,\n",
        "      'PREDICT_IN_FUTURE': PREDICT_IN_FUTURE,\n",
        "      'FLOW_INTERVAL': FLOW_INTERVAL,\n",
        "      'N_SPLITS': N_SPLITS,\n",
        "    }\n",
        "}\n",
        "\n",
        "data = retrieve_data(FLOW_INTERVAL)\n",
        "\n",
        "history, validation = rnn(data, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = history.model.predict(validation[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_prediction(validation[1], prediction, \"RNN-150\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5669f3d72740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RNN-150\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ],
      "source": [
        "ev = evaluate([validation[1]], [prediction], [0], \"RNN-150\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "store(ev, 'results', 'RNN-150')"
      ]
    }
  ]
}