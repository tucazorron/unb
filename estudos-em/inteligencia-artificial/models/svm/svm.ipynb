{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "source": [
        "## Libraries"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3tKGcLkrmvV"
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install pandas\n",
        "!pip3 install numpy\n",
        "!pip3 install sklearn\n",
        "!pip3 install statsmodels\n",
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "import pandas as pd # data manipulation library\n",
        "import numpy as np # math library\n",
        "\n",
        "import sklearn.metrics as sklm # metrics\n",
        "import skll.metrics as skllm\n",
        "import statsmodels as sm # statistical models\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/tuca/.local/lib/python3.8/site-packages (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/tuca/.local/lib/python3.8/site-packages (1.2.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /home/tuca/.local/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /home/tuca/.local/lib/python3.8/site-packages (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sklearn in /home/tuca/.local/lib/python3.8/site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /home/tuca/.local/lib/python3.8/site-packages (from sklearn) (0.24.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/tuca/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: statsmodels in /home/tuca/.local/lib/python3.8/site-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.21 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.2.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (1.6.3)\n",
            "Requirement already satisfied: patsy>=0.5 in /home/tuca/.local/lib/python3.8/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.21->statsmodels) (2019.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.21->statsmodels) (2.7.3)\n",
            "Requirement already satisfied: six in /home/tuca/.local/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/tuca/.local/lib/python3.8/site-packages (3.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.7.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/tuca/.local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six in /home/tuca/.local/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Utils"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WalkingForwardTimeSeriesSplit():\n",
        "  def __init__(self, n_splits):\n",
        "    self.n_splits = n_splits\n",
        "  \n",
        "  def get_n_splits(self, X, y, groups):\n",
        "    return self.n_splits\n",
        "  \n",
        "  def split(self, X, y=None, groups=None):\n",
        "    n_samples = len(X)\n",
        "    k_fold_size = n_samples // self.n_splits\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    margin = 0\n",
        "    for i in range(self.n_splits):\n",
        "      start = i * k_fold_size\n",
        "      stop = start + k_fold_size\n",
        "      mid = int(0.8 * (stop - start)) + start\n",
        "      yield indices[start: mid], indices[mid + margin: stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_cv_results(cv_results):\n",
        "  res = copy.deepcopy(cv_results)\n",
        "  for key in res:\n",
        "    if type(res[key]) != list: \n",
        "      res[key] = res[key].tolist()\n",
        "\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_data(flow_interval):\n",
        "    path = \"{0}dataset/dataset_flow_{1}.csv\".format(PATH, flow_interval)\n",
        "    print(PATH)\n",
        "    data = pd.read_csv(path, ';')\n",
        "    \n",
        "    data['Flow'].apply(int)\n",
        "    data['AveSpeed'].apply(float)\n",
        "    data['Density'].apply(float)\n",
        "    data['Sunday'].apply(int)\n",
        "    data['Monday'].apply(int)\n",
        "    data['Tuesday'].apply(int)\n",
        "    data['Wednesday'].apply(int)\n",
        "    data['Thursday'].apply(int)\n",
        "    data['Friday'].apply(int)\n",
        "    data['Saturday'].apply(int)\n",
        "      \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_json (obj):\n",
        "  print(json.dumps(obj, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store(obj, path, name):\n",
        "  with open(\"{0}{1}/{2}.json\".format(PATH, path, name), 'w') as json_file:\n",
        "    json.dump(obj, json_file, sort_keys=True, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_results ():\n",
        "  name = int(time.time())\n",
        "  \n",
        "  result_data['meta'] = {\n",
        "    \"SEEABLE_PAST\": SEEABLE_PAST,\n",
        "    \"PREDICT_IN_FUTURE\": PREDICT_IN_FUTURE,\n",
        "    \"FLOW_INTERVAL\": FLOW_INTERVAL,\n",
        "    \"N_SPLITS\": N_SPLITS,\n",
        "  }\n",
        "\n",
        "  store(result_data, \"results\", name)\n",
        "\n",
        "  slim_result_data = copy.deepcopy(result_data)\n",
        "  for model in slim_result_data['results']:\n",
        "      del slim_result_data['results'][model]['raw']\n",
        "\n",
        "  store(slim_result_data, \"results\", \"{0}_slim\".format(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_comparisons (title):\n",
        "  name = str(int(time.time()))\n",
        "  \n",
        "  j = copy.deepcopy(comparison_data)\n",
        "\n",
        "  store(j, \"results/comparison\", \"{0}_{1}\".format(title, name))\n",
        "    \n",
        "  for i in range(len(j)):\n",
        "    for model in j[i]['results']:\n",
        "      del j[i]['results'][model]['raw']\n",
        "\n",
        "  store(j, \"results/comparison\", \"{0}_{1}_slim\".format(title, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(data, useB, n_steps, n_future):\n",
        "  \"\"\" Generate Dataset\n",
        "  \n",
        "  Generate a dataset provided a sequence. Reshape the sequence in rolling intervals from [samples, timesteps] into \n",
        "  [samples, timesteps, features] and split the sequence. The split the sequence in rolling intervals with a corresponding value \n",
        "  like the example bellow.\n",
        "\n",
        "  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])\n",
        "  \n",
        "  Arguments:\n",
        "    raw_seq: the sequence to reshape.\n",
        "    useB: if the dataset is more complex or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "\n",
        "  sequence = np.array(data if useB else data['Flow'])\n",
        "\n",
        "  n = len(sequence)\n",
        "  X, Y = list(), list()\n",
        "\n",
        "  for i in range(n):\n",
        "    j = i + n_steps\n",
        "    k = j + n_future\n",
        "\n",
        "    if k >= n:\n",
        "      break\n",
        "\n",
        "    seq_x, seq_y = sequence[i:j], sequence[k]\n",
        "    X.append(seq_x)\t\n",
        "    Y.append(seq_y[0] if useB else seq_y)\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\t\n",
        "  \n",
        "  if not useB:\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate (expected, observed, times, name):\n",
        " \n",
        "  n = len(expected)\n",
        "  flatten = lambda l : [i for sl in l for i in sl]\n",
        "  \n",
        "  expected = list(map(list, expected))\n",
        "  observed = list(map(list, observed))\n",
        "  \n",
        "  for i in range(n):\n",
        "    expected[i] = list(map(float, expected[i]))\n",
        "    observed[i] = list(map(float, observed[i]))\n",
        "  \n",
        "  raw = evaluate_raw(expected, observed, times)\n",
        "  \n",
        "  eva = {\n",
        "    'TIME':         int(sum(times)),\n",
        "    'RMSE':         float(np.mean(raw['RMSE'])),\n",
        "    'MAE':          float(np.mean(raw['MAE'])),\n",
        "    'Kappa':        float(np.mean(raw['Kappa'])),\n",
        "    'HR':           float(np.mean(raw['HR'])),\n",
        "    'has_negative': (min(flatten(observed)) < 0),\n",
        "    'raw':          raw\n",
        "  }\n",
        "  \n",
        "  print(f\"\\n{name} Final Result:\")\n",
        "  print(f\"\\tTotal Time: {eva['TIME']}s\")\n",
        "  print(f\"\\tRMSE: {eva['RMSE']}\")\n",
        "  print(f\"\\tMAE: {eva['MAE']}\")\n",
        "  print(f\"\\tKappa: {eva['Kappa']}\")\n",
        "  print(f\"\\tHit Ratio: {eva['HR'] * 100}%\")\n",
        "    \n",
        "  return eva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_raw (expected, observed, times):\n",
        "  \n",
        "  n = len(expected)\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [0 if np.isnan(o) else o for o in observed[i]]\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [max(o, 0) for o in observed[i]]\n",
        "  \n",
        "  raw = {\n",
        "    'expected': expected,\n",
        "    'observed': observed,\n",
        "    'TIME':     times,\n",
        "    'RMSE':     [0] * n,\n",
        "    'MAE':      [0] * n,\n",
        "    'Kappa':    [0] * n,\n",
        "    'HR':       [0] * n,\n",
        "  }\n",
        "  \n",
        "  for i in range(n):\n",
        "    Y     = expected[i]\n",
        "    Y_hat = observed[i]\n",
        "    time  = times[i]\n",
        "\n",
        "    raw['RMSE'][i]  = np.sqrt(sklm.mean_squared_error(Y, Y_hat))\n",
        "    raw['MAE'][i]   = sklm.mean_absolute_error(Y, Y_hat)\n",
        "    raw['Kappa'][i] = skllm.kappa(Y, Y_hat)\n",
        "    raw['HR'][i]    = evaluate_precision_hit_ratio(Y, Y_hat)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      print(f\"({i+1}/{n}) Test Size: {len(Y)}, Time: {time}s\")\n",
        "      print(f\"\\tRMSE: {raw['RMSE'][i]}\")\n",
        "      print(f\"\\tMAE: {raw['MAE'][i]}\")\n",
        "      print(f\"\\tKappa: {raw['Kappa'][i]}\")\n",
        "      print(f\"\\tHit Ratio: {raw['HR'][i] * 100}%\")\n",
        "\n",
        "  return raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_precision_hit_ratio (Y, Y_hat):\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    if i < N_FUTURE:\n",
        "      continue\n",
        "      \n",
        "    exp = Y[i] - Y[i - N_FUTURE]\n",
        "    obs = Y_hat[i] - Y[i - N_FUTURE]\n",
        "    \n",
        "    if exp * obs > 0:\n",
        "      cnt += 1\n",
        "    \n",
        "  return cnt / len(Y)"
      ]
    },
    {
      "source": [
        "## Testing"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "SEEABLE_PAST = 480 # in minutes\n",
        "PREDICT_IN_FUTURE = 60 # in minutes\n",
        "FLOW_INTERVAL = 150 # the interval size for each flow\n",
        "N_SPLITS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derivated Model Parameters\n",
        "N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past\n",
        "N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next FLOW_INTERVAL minutes)\n",
        "DAY_SIZE = (24 * 60 * 60) // FLOW_INTERVAL  \n",
        "WEEK_SIZE = (7 * 24 * 60 * 60) // FLOW_INTERVAL\n",
        "VERBOSITY = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_svm_tuned(X, Y, useB):\n",
        "  param_grid = {\n",
        "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
        "    'gamma': list(np.logspace(-2, 2, 4)) + ['scale'],\n",
        "  }\n",
        "  model = svm.SVR(epsilon=0.2)\n",
        "  scoring = 'neg_mean_squared_error'\n",
        "  cv = WalkingForwardTimeSeriesSplit(n_splits=1)\n",
        "  n_jobs = 15\n",
        "\n",
        "  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose=2)\n",
        "\n",
        "  grid_search.fit(X, Y)\n",
        "    \n",
        "  res = {\n",
        "      'params': param_grid,\n",
        "      'best_params': grid_search.best_params_,\n",
        "      'score': clean_cv_results(grid_search.cv_results_),\n",
        "  }\n",
        "\n",
        "  return grid_search.best_estimator_, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def support_vector_machine(X, Y, useB=False,):\n",
        "  global result_data\n",
        "  \n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "\n",
        "  name = \"SVM B\" if useB else \"SVM A\"\n",
        "  expected, observed, times, grid_res = [], [], [], []\n",
        "  tscv = WalkingForwardTimeSeriesSplit(n_splits=N_SPLITS)\n",
        "\n",
        "  for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    model, res = get_svm_tuned(X_train, Y_train, useB)\n",
        "    model.fit(X_train, Y_train) \n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    grid_res.append(res)\n",
        "    observed.append(model.predict(X_test))\n",
        "    expected.append(Y_test)\n",
        "    times.append(end_time - start_time)\n",
        "    \n",
        "  res = evaluate(expected, observed, times, name)  \n",
        "\n",
        "  res['grid_res'] = grid_res\n",
        "\n",
        "  result_data['results'][name] = res\n",
        "\n",
        "  store(result_data['results'][name], \"results/grid\", \"{0}_{1}\".format(name, PREDICT_IN_FUTURE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "(1/8) Test Size: 1320, Time: 68.24463868141174s\n",
            "\tRMSE: 4.0789799283383354\n",
            "\tMAE: 2.9463283624753536\n",
            "\tKappa: 0.13088904403091084\n",
            "\tHit Ratio: 67.87878787878789%\n",
            "(2/8) Test Size: 1320, Time: 61.9749698638916s\n",
            "\tRMSE: 3.792278696137758\n",
            "\tMAE: 2.7784718155865846\n",
            "\tKappa: 0.08975887845030683\n",
            "\tHit Ratio: 61.66666666666667%\n",
            "(3/8) Test Size: 1320, Time: 61.1627151966095s\n",
            "\tRMSE: 4.3040327503933895\n",
            "\tMAE: 3.1510773620931545\n",
            "\tKappa: 0.09740509353231341\n",
            "\tHit Ratio: 65.75757575757576%\n",
            "(4/8) Test Size: 1320, Time: 57.629284620285034s\n",
            "\tRMSE: 3.853057117355775\n",
            "\tMAE: 2.735356640770824\n",
            "\tKappa: 0.13696290323462712\n",
            "\tHit Ratio: 64.92424242424242%\n",
            "(5/8) Test Size: 1320, Time: 55.13568592071533s\n",
            "\tRMSE: 4.46684310810978\n",
            "\tMAE: 3.2447608448045506\n",
            "\tKappa: 0.09454208288448374\n",
            "\tHit Ratio: 62.65151515151515%\n",
            "(6/8) Test Size: 1320, Time: 63.93692493438721s\n",
            "\tRMSE: 5.358661912508485\n",
            "\tMAE: 3.6650984055308484\n",
            "\tKappa: 0.08805786614953348\n",
            "\tHit Ratio: 66.89393939393939%\n",
            "(7/8) Test Size: 1320, Time: 64.34808254241943s\n",
            "\tRMSE: 4.69594383193412\n",
            "\tMAE: 3.140616883568935\n",
            "\tKappa: 0.12345229818184422\n",
            "\tHit Ratio: 66.28787878787878%\n",
            "(8/8) Test Size: 1320, Time: 59.40587854385376s\n",
            "\tRMSE: 3.628819405431381\n",
            "\tMAE: 2.6742260514904768\n",
            "\tKappa: 0.1282416419766802\n",
            "\tHit Ratio: 61.36363636363637%\n",
            "\n",
            "SVM A Final Result:\n",
            "\tTotal Time: 491s\n",
            "\tRMSE: 4.272327093776128\n",
            "\tMAE: 3.0419920457900913\n",
            "\tKappa: 0.11116372605508748\n",
            "\tHit Ratio: 64.6780303030303%\n"
          ]
        }
      ],
      "source": [
        "global result_data\n",
        "  \n",
        "result_data = {\n",
        "    'results': {},\n",
        "    'meta': {\n",
        "      'SEEABLE_PAST': SEEABLE_PAST,\n",
        "      'PREDICT_IN_FUTURE': PREDICT_IN_FUTURE,\n",
        "      'FLOW_INTERVAL': FLOW_INTERVAL,\n",
        "      'N_SPLITS': N_SPLITS,\n",
        "    }\n",
        "}\n",
        "\n",
        "data = retrieve_data(FLOW_INTERVAL)\n",
        "X_a, Y_a = generate_dataset(data, False, N_STEPS, N_FUTURE)\n",
        "support_vector_machine(X_a, Y_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_prediction (Y, Y_hat, title):\n",
        "  \"\"\" Plot Prediction\n",
        "  \n",
        "  Plot the prediction (Flow x Time) of what was expected and what\n",
        "  was predicted.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(len(Y)):\n",
        "    name = f\"{title} ({str(i+1).zfill(2)} of {len(Y)})\"\n",
        "    path = f\"plots/prediction/{name}\"\n",
        "    \n",
        "    plt.plot(Y[i])\n",
        "    plt.plot(Y_hat[i])\n",
        "    plt.title(f\"Predição do Modelo {title}\")\n",
        "    plt.ylabel('Fluxo')\n",
        "    plt.xlabel('Tempo')\n",
        "    plt.legend(['esperado', 'observado'], loc='upper left')\n",
        "    plt.rcdefaults()\n",
        "\n",
        "    plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "    # plt.savefig(path + \".pdf\")\n",
        "\n",
        "    plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "expected = result_data['results']['SVM A']['raw']['expected']\n",
        "observed = result_data['results']['SVM A']['raw']['observed']\n",
        "\n",
        "plot_prediction(expected, observed, \"SVM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}