{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "from deep_translator import GoogleTranslator\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collects tweets from twitter api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"covid OR pandemia lang:pt until:2021-05-11 since:2021-03-16\"\n",
    "dates = []\n",
    "locations = []\n",
    "tweets_pt = []\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    location = tweet.user.location\n",
    "    if location.find('Brasil') != -1:\n",
    "        date = str(tweet.date).split('+')[0]\n",
    "        dates.append(date)\n",
    "        locations.append(location)\n",
    "        tweets_pt.append(tweet.rawContent)\n",
    "        print(f'{date} => {len(tweets_pt)}', end='\\r')\n",
    "print(f'\\nDONE: {len(tweets_pt)} tweets collected')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocesses tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_proc = []\n",
    "for tweet in tweets_pt:\n",
    "    tweet_words = []\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = 'http'\n",
    "        tweet_words.append(word)\n",
    "    tweets_proc.append(\" \".join(tweet_words))\n",
    "    print(f'{len(tweets_proc)} / {len(tweets_pt)}', end='\\r')\n",
    "print(f'\\nDONE: {len(tweets_proc)} tweets preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'location': locations,\n",
    "    'tweet': tweets_proc\n",
    "})\n",
    "\n",
    "df_pt\n",
    "df_pt.to_csv('second_wave.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "translates tweets to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_en = GoogleTranslator(source='pt', target='en').translate_batch(tweets_proc)\n",
    "print(f'DONE: {len(tweets_en)} tweets translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'location': locations,\n",
    "    'tweet_pt': tweets_proc,\n",
    "    'tweet_en': tweets_en\n",
    "})\n",
    "df_en\n",
    "df_en.to_csv('df_en.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyzes sentiment of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for tweet in tweets_en:\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "    output = model(**encoded_tweet)\n",
    "    output_score = output[0][0].detach().numpy()\n",
    "    scores.append(softmax(output_score))\n",
    "    print(f'{len(scores)} / {len(tweets_en)}', end='\\r')\n",
    "print(f'\\nDONE: {len(scores)} tweets scored')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates a dataframe with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = [score[0] for score in scores]\n",
    "neutral = [score[1] for score in scores]\n",
    "positive = [score[2] for score in scores]\n",
    "label = [labels[score.argmax()] for score in scores]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'location': locations,\n",
    "    'tweets_pt': tweets_proc,\n",
    "    'tweets_en': tweets_en,\n",
    "    'negative': negative,\n",
    "    'neutral': neutral,\n",
    "    'positive': positive,\n",
    "    'label': label\n",
    "})\n",
    "\n",
    "df.to_csv('database.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculates the average sentiment of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [0, 0, 0]\n",
    "\n",
    "result[0] = sum(negative) / len(scores)\n",
    "result[1] = sum(neutral) / len(scores)\n",
    "result[2] = sum(positive) / len(scores)\n",
    "\n",
    "for i in range(3):\n",
    "    l = labels[i]\n",
    "    s = result[i]\n",
    "    print(l, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
